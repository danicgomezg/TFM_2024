# -*- coding: utf-8 -*-
"""validacion_cruzada.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14bJwq7K7PuIH4KlHj9-zhE0RkMKNq5Hc
"""

import pandas as pd

# Ruta del archivo CSV en Google Colab
ruta_archivo = '/content/Base_Fraude.csv'

# Cargar la base de datos desde el archivo CSV con motor 'python'
try:
    base_de_datos = pd.read_csv(ruta_archivo, delimiter=';', engine='python')
    # Muestra las primeras filas de la base de datos para verificar la carga
    print(base_de_datos.head())
except pd.errors.ParserError as e:
    print(f"Error al cargar el archivo CSV: {e}")

# Contar valores nulos en cada columna
valores_nulos_por_columna = base_de_datos.isnull().sum()

# Mostrar el resultado
print("Valores nulos por columna:")
print(valores_nulos_por_columna)

# Eliminar filas con valores nulos
base_de_datos_sin_nulos = base_de_datos.dropna()

# Mostrar la cantidad de filas después de eliminar los valores nulos
print("Número de filas después de eliminar los valores nulos:", len(base_de_datos_sin_nulos))

# Selección de columnas con menos valores nulos solapados
columnas_deseadas = [ 'Descripcion_Area_Rural', 'Furips_Descripcion', 'Ciudad', 'Marca_Vehiculo', 'Estado_Vehiculo_Descripcion',
                      'Tipo_Vehiculo_Descripcion', 'Tipo_Vehiculo', 'Condicion_Accidentado_Descripcion',
                      'Categoria_Descripcion_Eje10', 'Fraude']

nuevo_dataset = base_de_datos[columnas_deseadas].copy()

# Eliminar filas con valores nulos
base_de_datos_1 = nuevo_dataset.dropna()

# Mostrar la cantidad de filas después de eliminar los valores nulos
print("Número de filas después de eliminar los valores nulos:", len(base_de_datos_1))

# Mostrar el tipo de variable de cada columna en el nuevo dataset
tipos_de_variable = base_de_datos_1.dtypes

# Mostrar el resultado
print("Tipo de variable de cada columna en el nuevo dataset:")
print(tipos_de_variable)

# Mostrar filas seleccionadad  de la columna 'Categoria_Descripcion_Eje10'
primeras_tres_filas = base_de_datos_1.loc[15000:15003,'Furips_Descripcion']
print(primeras_tres_filas)

# Verificación de desequilibrio entre clases
# Convertir la columna "Fraude" a minúsculas y quitar espacios en blanco adicionales
base_de_datos_1['Fraude'] = base_de_datos_1['Fraude'].str.lower().str.strip()

# Contar las filas con el valor "si" en la columna "Fraude"
filas_con_fraude_si = base_de_datos_1[base_de_datos_1['Fraude'] == 'si'].shape[0]

# Contar las filas con el valor "no" en la columna "Fraude"
filas_con_fraude_no = base_de_datos_1[base_de_datos_1['Fraude'] == 'no'].shape[0]

# Mostrar los resultados
print(f"Filas con 'si' en la variable 'Fraude': {filas_con_fraude_si}")
print(f"Filas con 'no' en la variable 'Fraude': {filas_con_fraude_no}")

import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from gensim import corpora, models
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import GridSearchCV




# Descargar recursos de nltk
nltk.download('stopwords')
nltk.download('punkt')

# Funciones de preprocesamiento
def preprocess_text(text):
    stop_words = set(stopwords.words('spanish'))
    tokens = word_tokenize(text.lower())
    tokens_filtered = [token for token in tokens if token.isalnum() and token not in stop_words]
    return tokens_filtered

def encode_column(column):
    label_encoder = LabelEncoder()
    return label_encoder.fit_transform(column)

# Aplicar preprocesamiento solo a las variables de texto complejas
base_de_datos_1['Categoria_Descripcion_Eje10'] = base_de_datos_1['Categoria_Descripcion_Eje10'].apply(preprocess_text)
base_de_datos_1['Furips_Descripcion'] = base_de_datos_1['Furips_Descripcion'].apply(preprocess_text)

# Combinar todos los datos de texto en una serie única
text_data = base_de_datos_1.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)

# Tokenizar y preprocesar datos de texto
tokenized_text = text_data.apply(preprocess_text)

# Crear diccionario y corpus para LDA
dictionary = corpora.Dictionary(tokenized_text)
corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_text]

# Aplicar LDA
num_topics = 20
lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)

# Mostrar temas obtenidos por LDA
print("Temas obtenidos por LDA:")
for i, topic in enumerate(lda_model.print_topics()):
    print(f"Tema {i + 1}: {topic}")

# Crear conjunto de datos para entrenamiento y prueba
X_text = text_data.apply(lambda x: ' '.join(x))
y = base_de_datos_1['Fraude']

# Convertir etiquetas de clase a formato numérico
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Definir número de divisiones para StratifiedKFold
n_splits = 5
skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

# Inicializar listas para almacenar métricas para cada división
all_metrics_nn = []
all_metrics_rf = []
all_metrics_svm = []


for train_index, test_index in skf.split(X_text, y):
    X_train, X_test = X_text.iloc[train_index], X_text.iloc[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # Tokenización y relleno
    max_words = 1000
    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(X_train)

    X_train_sequences = tokenizer.texts_to_sequences(X_train)
    X_test_sequences = tokenizer.texts_to_sequences(X_test)

    X_train_pad = pad_sequences(X_train_sequences, maxlen=37)
    X_test_pad = pad_sequences(X_test_sequences, maxlen=37)

    # Modelo de Red Neuronal
    model_nn = Sequential()
    model_nn.add(Embedding(input_dim=max_words, output_dim=128, input_length=37))
    model_nn.add(SpatialDropout1D(0.2))
    model_nn.add(LSTM(70))
    model_nn.add(Dropout(0.2))
    model_nn.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))
    model_nn.add(Dropout(0.2))
    model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    early_stopping_nn = EarlyStopping(monitor='val_loss', patience=3)
    reduce_lr_nn = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)
    history_nn = model_nn.fit(X_train_pad, y_train, epochs=10, validation_data=(X_test_pad, y_test), callbacks=[early_stopping_nn, reduce_lr_nn])

    y_pred_nn = (model_nn.predict(X_test_pad) > 0.5).astype("int32")
    accuracy_nn = accuracy_score(y_test, y_pred_nn)
    precision_nn = precision_score(y_test, y_pred_nn)
    recall_nn = recall_score(y_test, y_pred_nn)
    f1_nn = f1_score(y_test, y_pred_nn)
    conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)
    roc_auc_nn = roc_auc_score(y_test, y_pred_nn)
    all_metrics_nn.append((accuracy_nn, precision_nn, recall_nn, f1_nn, conf_matrix_nn, roc_auc_nn))

    # Modelo de Bosque Aleatorio (Random Forest)
    model_rf = RandomForestClassifier(random_state=42)
    model_rf.fit(X_train_pad, y_train)
    y_pred_rf = model_rf.predict(X_test_pad)
    accuracy_rf = accuracy_score(y_test, y_pred_rf)
    precision_rf = precision_score(y_test, y_pred_rf)
    recall_rf = recall_score(y_test, y_pred_rf)
    f1_rf = f1_score(y_test, y_pred_rf)
    conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
    roc_auc_rf = roc_auc_score(y_test, y_pred_rf)
    all_metrics_rf.append((accuracy_rf, precision_rf, recall_rf, f1_rf, conf_matrix_rf, roc_auc_rf))

    # Modelo de Máquina de Soporte Vectorial con búsqueda de hiperparámetros
    parameters = {
        'C': [0.1, 1, 10, 100],  # Valores comunes de C para probar
        'kernel': ['linear', 'rbf'],
        'class_weight': ['balanced', None]
    }

    model_svm = SVC(probability=True, random_state=42)
    clf = GridSearchCV(model_svm, parameters, cv=5, scoring='accuracy')
    clf.fit(X_train_pad, y_train)

    # Mejor modelo encontrado
    best_model_svm = clf.best_estimator_

    # Predicciones
    y_pred_svm = best_model_svm.predict(X_test_pad)
    # # Métricas de rendimiento
    accuracy_svm = accuracy_score(y_test, y_pred_svm)
    precision_svm = precision_score(y_test, y_pred_svm)
    recall_svm = recall_score(y_test, y_pred_svm)
    f1_svm = f1_score(y_test, y_pred_svm)
    conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
    roc_auc_svm = roc_auc_score(y_test, y_pred_svm)
    all_metrics_svm.append((accuracy_svm, precision_svm, recall_svm, f1_svm, conf_matrix_svm, roc_auc_svm))



# Métricas promedio sobre divisiones
avg_metrics_nn = tuple(map(lambda x: sum(x) / len(all_metrics_nn), zip(*all_metrics_nn)))
avg_metrics_rf = tuple(map(lambda x: sum(x) / len(all_metrics_rf), zip(*all_metrics_rf)))
avg_metrics_svm = tuple(map(lambda x: sum(x) / len(all_metrics_svm), zip(*all_metrics_svm)))


# Imprimir métricas promedio para Red Neuronal
print("\nMétricas Promedio para Red Neuronal:")
print(f"Exactitud: {avg_metrics_nn[0]}")
print(f"Precisión: {avg_metrics_nn[1]}")
print(f"Recall: {avg_metrics_nn[2]}")
print(f"Puntuación F1: {avg_metrics_nn[3]}")
print("Matriz de Confusión Promedio:")
print(avg_metrics_nn[4])
print(f"Área bajo la curva ROC promedio: {avg_metrics_nn[5]}")

# Imprimir métricas promedio para Bosque Aleatorio (Random Forest)
print("\nMétricas Promedio para Bosque Aleatorio:")
print(f"Exactitud: {avg_metrics_rf[0]}")
print(f"Precisión: {avg_metrics_rf[1]}")
print(f"Recall: {avg_metrics_rf[2]}")
print(f"Puntuación F1: {avg_metrics_rf[3]}")
print("Matriz de Confusión Promedio:")
print(avg_metrics_rf[4])
print(f"Área bajo la curva ROC promedio: {avg_metrics_rf[5]}")

# Imprimir métricas promedio para Máquina de Soporte Vectorial (Support Vector Machine)
print("\nMétricas Promedio para Máquina de Soporte Vectorial:")
print(f"Exactitud: {avg_metrics_svm[0]}")
print(f"Precisión: {avg_metrics_svm[1]}")
print(f"Recall: {avg_metrics_svm[2]}")
print(f"Puntuación F1: {avg_metrics_svm[3]}")
print("Matriz de Confusión Promedio:")
print(avg_metrics_svm[4])
print(f"Área bajo la curva ROC promedio: {avg_metrics_svm[5]}")

# Importar las bibliotecas necesarias
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator

# Configurar el tamaño y estilo de las subgráficas
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# Neural Network ROC curve
fpr_nn, tpr_nn, _ = roc_curve(y_test, y_pred_nn)
roc_auc_nn = auc(fpr_nn, tpr_nn)
axs[0].plot(fpr_nn, tpr_nn, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_nn:.2f})')
axs[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
axs[0].set_xlabel('Tasa de Falsos Positivos')
axs[0].set_ylabel('Tasa de Verdaderos Positivos')
axs[0].set_title('NN')
axs[0].legend(loc='lower right')
axs[0].grid(True)

# Random Forest ROC curve
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)
axs[1].plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'ROC curve (area = {roc_auc_rf:.2f})')
axs[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
axs[1].set_xlabel('Tasa de Falsos Positivos')
axs[1].set_ylabel('Tasa de Verdaderos Positivos')
axs[1].set_title('RF')
axs[1].legend(loc='lower right')
axs[1].grid(True)

# Support Vector Machine ROC curve
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_svm)
roc_auc_svm = auc(fpr_svm, tpr_svm)
axs[2].plot(fpr_svm, tpr_svm, color='blue', lw=2, label=f'ROC curve (area = {roc_auc_svm:.2f})')
axs[2].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
axs[2].set_xlabel('Tasa de Falsos Positivos')
axs[2].set_ylabel('Tasa de Verdaderos Positivos')
axs[2].set_title('SVM')
axs[2].legend(loc='lower right')
axs[2].grid(True)

# Ajustar los ejes y mostrar el gráfico
for ax in axs:
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Mostrar números enteros en los ejes X
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Configurar el tamaño de la figura
plt.figure(figsize=(18, 6))

# Red neuronal matriz de confusión
plt.subplot(1, 3, 1)
sns.heatmap(avg_metrics_nn[4], annot=True, fmt='g', cmap='Blues', annot_kws={'size': 14})
plt.title('Matriz de Confusión Promedio - Red Neuronal')
plt.xlabel('Predicho')
plt.ylabel('Real')

# Random Forest matriz de confusión
plt.subplot(1, 3, 2)
sns.heatmap(avg_metrics_rf[4], annot=True, fmt='g', cmap='Blues', annot_kws={'size': 14})
plt.title('Matriz de Confusión Promedio - Bosque Aleatorio')
plt.xlabel('Predicho')
plt.ylabel('Real')

# Máquina de Soporte Vectoria matriz de confusión
plt.subplot(1, 3, 3)
sns.heatmap(avg_metrics_svm[4], annot=True, fmt='g', cmap='Blues', annot_kws={'size': 14})
plt.title('Matriz de Confusión Promedio - Máquina de Soporte Vectorial')
plt.xlabel('Predicho')
plt.ylabel('Real')

# Mostrar la figura
plt.show()

#Comprobar coherencia en el número de temas
from gensim.models import LdaModel, CoherenceModel
import matplotlib.pyplot as plt

# Definir un rango de números de temas para probar
num_topics_range = [5, 10, 15, 20, 25, 30, 40, 50, 60]

coherence_scores = []

# Iterar sobre diferentes números de temas
for num_topics in num_topics_range:
    # Crear el modelo LDA
    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)

    # Calcular la coherencia del modelo
    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_text, dictionary=dictionary, coherence='c_v')
    coherence_score = coherence_model.get_coherence()

    coherence_scores.append(coherence_score)

# Graficar los resultados
plt.plot(num_topics_range, coherence_scores, marker='o')
plt.xlabel('Número de Temas')
plt.ylabel('Puntuación de Coherencia')
plt.title('Evaluación de Coherencia para Diferentes Números de Temas en LDA')
plt.show()