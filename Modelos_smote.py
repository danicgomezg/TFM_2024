# -*- coding: utf-8 -*-
"""smote.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wnauDOfLC_Mno4tvtdghVrN7GPJVYYEt
"""

import pandas as pd

# Ruta del archivo CSV en Google Colab
ruta_archivo = '/content/Base_Fraude.csv'

# Cargar la base de datos desde el archivo CSV con motor 'python'
try:
    base_de_datos = pd.read_csv(ruta_archivo, delimiter=';', engine='python')
    # Muestra las primeras filas de la base de datos para verificar la carga
    print(base_de_datos.head())
except pd.errors.ParserError as e:
    print(f"Error al cargar el archivo CSV: {e}")

columnas_deseadas = [ 'Descripcion_Area_Rural', 'Furips_Descripcion', 'Ciudad', 'Marca_Vehiculo', 'Estado_Vehiculo_Descripcion',
                      'Tipo_Vehiculo_Descripcion', 'Tipo_Vehiculo', 'Condicion_Accidentado_Descripcion',
                      'Categoria_Descripcion_Eje10', 'Fraude']

nuevo_dataset = base_de_datos[columnas_deseadas].copy()

# Eliminar filas con valores nulos
base_de_datos_1 = nuevo_dataset.dropna()

# Mostrar la cantidad de filas después de eliminar los valores nulos
print("Número de filas después de eliminar los valores nulos:", len(base_de_datos_1))

# Eliminar valores nulos y reiniciar los indices del dataframe
base_de_datos_1 = base_de_datos_1.dropna().reset_index(drop=True)

import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from gensim import corpora, models
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from imblearn.over_sampling import SMOTE
from imblearn.keras import BalancedBatchGenerator
from sklearn.model_selection import GridSearchCV

# Descarga recursos de nltk
nltk.download('stopwords')
nltk.download('punkt')

# Función de preprocesamiento
def preprocess_text(text):
    stop_words = set(stopwords.words('spanish'))
    tokens = word_tokenize(text.lower())
    tokens_filtered = [token for token in tokens if token.isalnum() and token not in stop_words]
    return tokens_filtered

def encode_column(column):
    label_encoder = LabelEncoder()
    return label_encoder.fit_transform(column)

# Aplicar preprocesamiento solo a las variables de texto complejo
base_de_datos_1['Categoria_Descripcion_Eje10'] = base_de_datos_1['Categoria_Descripcion_Eje10'].apply(preprocess_text)
base_de_datos_1['Furips_Descripcion'] = base_de_datos_1['Furips_Descripcion'].apply(preprocess_text)

# Combinar todos los datos de texto en una única serie
text_data = base_de_datos_1.apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)

# Tokenizar y preprocesar los datos de texto
tokenized_text = text_data.apply(preprocess_text)

# Crear diccionario y corpus para LDA
dictionary = corpora.Dictionary(tokenized_text)
corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_text]

# Aplicar LDA
num_topics = 20
lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)

# Mostrar los temas obtenidos por LDA
print("Topics obtained by LDA:")
for i, topic in enumerate(lda_model.print_topics()):
    print(f"Topic {i + 1}: {topic}")

# Conjunto de datos para entrenamiento y prueba
X_text = text_data.apply(lambda x: ' '.join(x))
y = base_de_datos_1['Fraude']

# Convertir etiquetas de clases a formato numérico
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.3, random_state=42, stratify=y)

# Tokenización y Relleno dentro del bucle de validación cruzada
max_words = 1000
tokenizer = Tokenizer(num_words=max_words)

# Ajustar el tokenizador solo con los datos de entrenamiento
tokenizer.fit_on_texts(X_train)

# Transformar tanto los datos de entrenamiento como los de prueba en secuencias
X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_test_sequences = tokenizer.texts_to_sequences(X_test)

# Rellenar secuencias
X_train_pad = pad_sequences(X_train_sequences, maxlen=37)
X_test_pad = pad_sequences(X_test_sequences, maxlen=37)

# Optimizar parámetros de SMOTE utilizando GridSearchCV
param_grid = {
    'sampling_strategy': [0.5, 0.7, 0.9],  # You can modify these values based on your needs
    'k_neighbors': [5, 7, 8]  # You can modify these values based on your needs
}

smote = SMOTE(random_state=42)
grid_search = GridSearchCV(smote, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid_search.fit(X_train_pad, y_train)

# Obtener los mejores parámetros de SMOTE
best_smote_params = grid_search.best_params_

# Aplicar SMOTE con los mejores parámetros solo en los datos de entrenamiento
best_smote = SMOTE(sampling_strategy=best_smote_params['sampling_strategy'], k_neighbors=best_smote_params['k_neighbors'], random_state=42)
X_resampled, y_resampled = best_smote.fit_resample(X_train_pad, y_train)

# Crear el modelo de Red Neuronal Profunda
model_nn = Sequential()
model_nn.add(Embedding(input_dim=max_words, output_dim=128, input_length=37))
model_nn.add(SpatialDropout1D(0.2))
model_nn.add(LSTM(70))
model_nn.add(Dropout(0.2))
model_nn.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))  #  L2 se usa para regularizar el modelo
model_nn.add(Dropout(0.1))

model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Entrenar el modelo con el generador de lotes balanceados
training_generator_nn = BalancedBatchGenerator(X_resampled, y_resampled, batch_size=32, random_state=42)
validation_data_nn = (X_test_pad, y_test)

# Agregar detención temprana con paciencia y reducir la tasa de aprendizaje
early_stopping_nn = EarlyStopping(monitor='val_loss', patience=4)
reduce_lr_nn = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)

# Etrenar el modelo
history_nn = model_nn.fit(training_generator_nn, epochs=10, validation_data=validation_data_nn, callbacks=[early_stopping_nn, reduce_lr_nn])


# Hacer predicciones en el conjunto de prueba
y_pred_nn = (model_nn.predict(X_test_pad) > 0.5).astype("int32")

# Calcular métricas para la red neuronal
accuracy_nn = accuracy_score(y_test, y_pred_nn)
precision_nn = precision_score(y_test, y_pred_nn)
recall_nn = recall_score(y_test, y_pred_nn)
f1_nn = f1_score(y_test, y_pred_nn)
conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)
roc_auc_nn = roc_auc_score(y_test, y_pred_nn)

# Graficar la curva ROC
fpr_nn, tpr_nn, _ = roc_curve(y_test, y_pred_nn)
roc_auc_nn = auc(fpr_nn, tpr_nn)
plt.figure(figsize=(8, 8))
plt.plot(fpr_nn, tpr_nn, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_nn:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Característica Operativa del Receptor (ROC) - Red Neuronal')
plt.legend(loc='lower right')
plt.show()

# Imprimir métricas para la Red Neuronal
print("Metrics for Neural Network:")
print(f"Accuracy: {accuracy_nn}")
print(f"Precision: {precision_nn}")
print(f"Recall: {recall_nn}")
print(f"F1-score: {f1_nn}")
print("Confusion Matrix:")
print(conf_matrix_nn)
print(f"ROC AUC: {roc_auc_nn}")

# Random Forest
model_rf = RandomForestClassifier(random_state=42)
model_rf.fit(X_resampled, y_resampled)

# Hacer predicciones en el conjunto de prueba
y_pred_rf = model_rf.predict(X_test_pad)

# Calcular métricas para Random Forest
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
roc_auc_rf = roc_auc_score(y_test, y_pred_rf)

# Graficar curva ROC
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)
plt.figure(figsize=(8, 8))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_rf:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - Random Forest')
plt.legend(loc='lower right')
plt.show()

# Imprimir métricas para Random Forest
print("\nMetrics for Random Forest:")
print(f"Accuracy: {accuracy_rf}")
print(f"Precision: {precision_rf}")
print(f"Recall: {recall_rf}")
print(f"F1-score: {f1_rf}")
print("Confusion Matrix:")
print(conf_matrix_rf)
print(f"ROC AUC: {roc_auc_rf}")

# Modelo de Máquina de Soporte Vectorial con búsqueda de hiperparámetros
parameters = {
    'C': [0.1, 1, 10, 100],  # Valores comunes de C para probar
    'kernel': ['linear', 'rbf'],  # Puedes probar diferentes kernels
        'class_weight': ['balanced', None]  # Para manejar clases desequilibradas
    }

model_svm = SVC(probability=True, random_state=42)
clf = GridSearchCV(model_svm, parameters, cv=5, scoring='accuracy')  # 5-fold cross-validation
clf.fit(X_train_pad, y_train)

# Mejor modelo encontrado
best_model_svm = clf.best_estimator_

# Predicciones
y_pred_svm = best_model_svm.predict(X_test_pad)

# Calcular métricas para la Máquina de Soporte Vectorial
accuracy_svm = accuracy_score(y_test, y_pred_svm)
precision_svm = precision_score(y_test, y_pred_svm)
recall_svm = recall_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm)
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
roc_auc_svm = roc_auc_score(y_test, y_pred_svm)

# Graficar la curva ROC
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_svm)
roc_auc_svm = auc(fpr_svm, tpr_svm)
plt.figure(figsize=(8, 8))
plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_svm:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Característica Operativa del Receptor (ROC) - Máquina de Soporte Vectorial')
plt.legend(loc='lower right')
plt.show()

# Imprimir métricas para  para Máquina de Vectores de Soporte
print("\nMetrics for Support Vector Machine:")
print(f"Accuracy: {accuracy_svm}")
print(f"Precision: {precision_svm}")
print(f"Recall: {recall_svm}")
print(f"F1-score: {f1_svm}")
print("Confusion Matrix:")
print(conf_matrix_svm)
print(f"ROC AUC: {roc_auc_svm}")

import matplotlib.pyplot as plt

# Visualiza curvas de aprendizaje
plt.plot(history_nn.history['loss'], label='Training Loss')
plt.plot(history_nn.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history_nn.history['accuracy'], label='Training Accuracy')
plt.plot(history_nn.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Validar la distribución después de SMOTE
print("Distribución de clases después de SMOTE:")
print(pd.Series(y_resampled).value_counts())

from sklearn.tree import DecisionTreeClassifier

# Crear y entrenar el modelo de Árbol de Decisión
model_dt = DecisionTreeClassifier(random_state=42)
model_dt.fit(X_resampled, y_resampled)

# Hacer predicciones en el conjunto de prueba
y_pred_dt = model_dt.predict(X_test_pad)

# Calcular métricas para el Árbol de Decisión
accuracy_dt = accuracy_score(y_test, y_pred_dt)
precision_dt = precision_score(y_test, y_pred_dt)
recall_dt = recall_score(y_test, y_pred_dt)
f1_dt = f1_score(y_test, y_pred_dt)
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)
roc_auc_dt = roc_auc_score(y_test, y_pred_dt)

# Graficar la curva ROC
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_dt)
roc_auc_dt = auc(fpr_dt, tpr_dt)
plt.figure(figsize=(8, 8))
plt.plot(fpr_dt, tpr_dt, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_dt:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - Árbol de Decisión')
plt.legend(loc='lower right')
plt.show()

# Imprimir métricas para el Árbol de Decisión
print("\nMetrics for Decision Tree:")
print(f"Accuracy: {accuracy_dt}")
print(f"Precision: {precision_dt}")
print(f"Recall: {recall_dt}")
print(f"F1-score: {f1_dt}")
print("Confusion Matrix:")
print(conf_matrix_dt)
print(f"ROC AUC: {roc_auc_dt}")